{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70cf3e7",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트와 XGBOOST를 사용한 특징의 중요도 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9816f0e",
   "metadata": {},
   "source": [
    "### 학습 내용\n",
    " * 랜덤 포레스트를 활용한 특징의 중요도\n",
    " * XGBOOST를 사용한 특징의 중요도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a954bf",
   "metadata": {},
   "source": [
    "### 랜덤 포레스를 활용한 특징의 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa64088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest importance\n",
      "['medical_info_a1' 'weight' 'age' 'medical_info_a2' 'height'] [0.12604874 0.11164059 0.07741062 0.07132529 0.05367491]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------\n",
    "# 랜덤포레스트 특징의 중요도\n",
    "# ---------------------------------\n",
    "# train_x는 학습 데이터, train_y는 목적 변수\n",
    "# 결손값을 취급할 수 없기 때문에 결손값을 보완한 데이터를 불러온다.\n",
    "train = pd.read_csv('../input/sample-data/train_preprocessed_onehot.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "# ---------------------------------\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 랜덤 포레스트 모델\n",
    "clf = RandomForestClassifier(n_estimators=10, random_state=71)\n",
    "clf.fit(train_x, train_y)\n",
    "fi = clf.feature_importances_\n",
    "\n",
    "# 중요도의 상위를 출력\n",
    "idx = np.argsort(fi)[::-1]\n",
    "top_cols, top_importances = train_x.columns.values[idx][:5], fi[idx][:5]\n",
    "print('random forest importance')\n",
    "print(top_cols, top_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a733bb",
   "metadata": {},
   "source": [
    "### XGBOOST를 활용한 특징의 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e67ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost importance\n",
      "[('weight', 2614.029296875), ('medical_info_a1', 2240.90283203125), ('height', 1973.3414306640625), ('age', 1442.831298828125), ('medical_info_a2', 1150.68603515625)]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# xgboost의 특징 중요도\n",
    "# ---------------------------------\n",
    "# train_x는 학습 데이터, train_y는 목적 변수\n",
    "train = pd.read_csv('../input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "# ---------------------------------\n",
    "import xgboost as xgb\n",
    "\n",
    "# xgboost\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "# params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}  # 기존\n",
    "params = {'objective': 'binary:logistic', 'verbosity': 0, 'random_state': 71}  # 이슈 대응 수정 2021/02/28\n",
    "num_round = 50\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# 중요도의 상위를 출력\n",
    "fscore = model.get_score(importance_type='total_gain')\n",
    "fscore = sorted([(k, v) for k, v in fscore.items()], key=lambda tpl: tpl[1], reverse=True)\n",
    "print('xgboost importance')\n",
    "print(fscore[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
