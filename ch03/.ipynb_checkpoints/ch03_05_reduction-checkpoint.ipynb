{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc68ba9",
   "metadata": {},
   "source": [
    "### 다양한 데이터 변환 - PCA, NMF, LDA 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d17688",
   "metadata": {},
   "source": [
    "### 학습 내용\n",
    "  * 데이터 준비\n",
    "  * PCA\n",
    "  * TruncatedSVD\n",
    "  * NMF\n",
    "  * LDA\n",
    "  * t-sne\n",
    "  * UMAP\n",
    "  * 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b5918",
   "metadata": {},
   "source": [
    "### 데이터 및 라이브러리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82dc9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# 데이터 등 준비\n",
    "# ----------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_x는 학습 데이터, train_y는 목적 변수, test_x는 테스트 데이터\n",
    "# pandas의 DataFrame, Series의 자료형 사용(numpy의 array로 값을 저장하기도 함.)\n",
    "\n",
    "train = pd.read_csv('../input/sample-data/train_preprocessed_onehot.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../input/sample-data/test_preprocessed_onehot.csv')\n",
    "\n",
    "# 설명용으로 학습 데이터와 테스트 데이터의 원래 상태를 복제해 두기\n",
    "train_x_saved = train_x.copy()\n",
    "test_x_saved = test_x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3beefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 표준화한 학습 데이터와 테스트 데이터를 반환하는 함수\n",
    "def load_standarized_data():\n",
    "    train_x, test_x = train_x_saved.copy(), test_x_saved.copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_x)\n",
    "    train_x = scaler.transform(train_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "    return pd.DataFrame(train_x), pd.DataFrame(test_x)\n",
    "\n",
    "\n",
    "# MinMax 스케일링을 수행한 학습 데이터와 테스트 데이터를 반환하는 함수\n",
    "def load_minmax_scaled_data():\n",
    "    train_x, test_x = train_x_saved.copy(), test_x_saved.copy()\n",
    "\n",
    "    # Min-Max Scaling 진행\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(pd.concat([train_x, test_x], axis=0))\n",
    "    train_x = scaler.transform(train_x)\n",
    "    test_x = scaler.transform(test_x)\n",
    "\n",
    "    return pd.DataFrame(train_x), pd.DataFrame(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcc0de",
   "metadata": {},
   "source": [
    "### 주성분 분석 - PCA(Principal Component Analysis)\n",
    " * 다변량 데이터의 주성분을 추출하여 데이터를 저차원 공간으로 변환하는 방법."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28698100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화된 데이터를 사용\n",
    "train_x, test_x = load_standarized_data()\n",
    "# -----------------------------------\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 데이터는 표준화 등의 스케일을 갖추기 위한 전처리가 이루어져야 함\n",
    "\n",
    "# 학습 데이터를 기반으로 PCA에 의한 변환을 정의\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(train_x)\n",
    "\n",
    "# 변환 적용\n",
    "train_x = pca.transform(train_x)\n",
    "test_x = pca.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee17353",
   "metadata": {},
   "source": [
    "### TruncatedSVD\n",
    " * 특이값 분해(Singular Value Decomposition, SVD)의 일종으로 행렬의 차원을 축소하기 위해 사용되는 기법.\n",
    " * 주성분 분석(PCA)의 변형."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb0767cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# 표준화된 데이터를 사용\n",
    "train_x, test_x = load_standarized_data()\n",
    "# -----------------------------------\n",
    "# TruncatedSVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 데이터는 표준화 등의 스케일을 갖추기 위한 전처리가 이루어져야 함\n",
    "\n",
    "# 학습 데이터를 기반으로 SVD를 통한 변환 정의\n",
    "svd = TruncatedSVD(n_components=5, random_state=71)\n",
    "svd.fit(train_x)\n",
    "\n",
    "# 변환 적용\n",
    "train_x = svd.transform(train_x)\n",
    "test_x = svd.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a419d231",
   "metadata": {},
   "source": [
    "### NMF(Non-Negative Matrix Factorization)\n",
    " * 비음수 행렬 분해의 일종.\n",
    " * 주어진 비음수 행렬을 두 개의 비음수 행렬의 곱으로 분해하는 방법.\n",
    " * NMF는 음수 값이 없는 행렬 데이터에 적용.\n",
    " * 데이터의 특징을 추출하거나 차원 축소를 위해 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04eab2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비음수의 값이기 때문에 MinMax스케일링을 수행한 데이터를 이용\n",
    "train_x, test_x = load_minmax_scaled_data()\n",
    "# -----------------------------------\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# 데이터는 음수가 아닌 값으로 구성\n",
    "\n",
    "# 학습 데이터를 기반으로 NMF에 의한 변환 정의\n",
    "model = NMF(n_components=5, init='random', random_state=71)\n",
    "model.fit(train_x)\n",
    "\n",
    "# 변환 적용\n",
    "train_x = model.transform(train_x)\n",
    "test_x = model.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3d64a",
   "metadata": {},
   "source": [
    "### LDA(LatentDirichletAllocation)\n",
    " * 토픽 모델링의 하나의 종류\n",
    " * 텍스트 데이터에 적용되어 주제(topic)의 구조를 추론하는 확률적 생성 모델\n",
    " * LDA는 비지도 학습 알고리즘.\n",
    " * 주어진 문서 집합에서 각 문서가 어떤 주제들로 구성되어 있는지를 추론하고, 주제와 단어간의 관계를 모델링\n",
    " * 주로 텍스트 데이터에서 주제를 추출하고, 문서간의 유사성을 평가하는데 사용된다.\n",
    " * 텍스트 분석, 문서 요약, 토픽 추천, 정보 검색 등 다양한 분야에서 활용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8a3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# LatentDirichletAllocation\n",
    "# -----------------------------------\n",
    "# MinMax스케일링을 수행한 데이터를 이용\n",
    "# 카운트 행렬은 아니지만, 음수가 아닌 값이면 계산 가능\n",
    "train_x, test_x = load_minmax_scaled_data()\n",
    "# -----------------------------------\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# 데이터는 단어-문서의 카운트 행렬 등으로 함\n",
    "\n",
    "# 학습 데이터를 기반으로 LDA에 의한 변환을 정의\n",
    "model = LatentDirichletAllocation(n_components=5, random_state=71)\n",
    "model.fit(train_x)\n",
    "\n",
    "# 변환 적용\n",
    "train_x = model.transform(train_x)\n",
    "test_x = model.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef293829",
   "metadata": {},
   "source": [
    "### LDA(LinearDiscriminantAnalysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8b774",
   "metadata": {},
   "source": [
    "* 선형 판별 분석(LDA)은 분류 문제에서 사용되는 머신러닝 알고리즘.\n",
    "* 두개 이상의 클래스에 속하는 데이터를 분류하는데 사용.\n",
    "* LDA는 차원을 줄이고 클래스간 분산을 최대화하고, 클래스 내 분산을 최소화하는 방식으로 데이터를 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3111c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# LinearDiscriminantAnalysis\n",
    "# -----------------------------------\n",
    "# 표준화된 데이터를 사용\n",
    "train_x, test_x = load_standarized_data()\n",
    "# -----------------------------------\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# 데이터는 단어-문서의 카운트 행렬 등으로 함\n",
    "\n",
    "# 학습 데이터를 기반으로 LDA에 의한 변환을 정의\n",
    "lda = LDA(n_components=1)\n",
    "lda.fit(train_x, train_y)\n",
    "\n",
    "# 변환 적용\n",
    "train_x = lda.transform(train_x)\n",
    "test_x = lda.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d0fd7",
   "metadata": {},
   "source": [
    "### t-sne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601af074",
   "metadata": {},
   "source": [
    " * 2023/06 확인 결과 bhtsne에서 에러 발생, 최신 버전에 맞춰, TSNE로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54083c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "948c1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel_wj\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\daniel_wj\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 표준화된 데이터를 사용\n",
    "train_x, test_x = load_standarized_data()\n",
    "# -----------------------------------\n",
    "\n",
    "# 데이터는 표준화 등의 스케일을 갖추기 위한 전처리가 이루어져야 함\n",
    "## 주석처리(23/06)\n",
    "#import bhtsne\n",
    "## t-sne에 의한 변환 - \n",
    "# data = pd.concat([train_x, test_x])\n",
    "# embedded = bhtsne.tsne(data.astype(np.float64), dimensions=2, rand_seed=71)\n",
    "\n",
    "# t-SNE에 의한 변환(23/06/21 수정)\n",
    "data = pd.concat([train_x, test_x])\n",
    "tsne = TSNE(n_components=2, random_state=71)\n",
    "embedded = tsne.fit_transform(data.astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ce123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 - 23/06 추가 \n",
    "plt.scatter(embedded[:, 0], embedded[:, 1], c=train_x['label'], s=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a8911",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f372c30",
   "metadata": {},
   "source": [
    "* 2023/06 확인 결과 에러 발생, 추후 확인 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "11c742f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00667ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17572\\2173433651.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 학습 데이터를 기반으로 UMAP에 의한 변환을 정의\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# um = umap.UMAP()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUMAP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "# 표준화된 데이터를 사용\n",
    "train_x, test_x = load_standarized_data()\n",
    "# -----------------------------------\n",
    "\n",
    "# 데이터는 표준화 등의 스케일을 갖추는 전처리가 이루어져야 함\n",
    "\n",
    "# 학습 데이터를 기반으로 UMAP에 의한 변환을 정의\n",
    "# um = umap.UMAP()\n",
    "um = umap.UMAP()\n",
    "um.fit(train_x)\n",
    "\n",
    "# 변환 적용\n",
    "train_x = um.transform(train_x)\n",
    "test_x = um.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c454e6",
   "metadata": {},
   "source": [
    "### 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac51e90",
   "metadata": {},
   "source": [
    "* 2023/06 확인 결과 에러 발생, 추후 확인 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb6a5004",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17572\\3172947421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# 학습 데이터를 기반으로 Mini-Batch K-Means를 통한 변환 정의\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m71\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# 해당 클러스터를 예측\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1912\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_center_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_mkl_vcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m         \u001b[1;31m# precompute squared norms of data points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_mkl_vcomp\u001b[1;34m(self, X, n_samples)\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \u001b[0mactive_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mCHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mactive_threads\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m             \u001b[0mmodules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthreadpool_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m             \u001b[0mhas_vcomp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"vcomp\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"prefix\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             has_mkl = (\"mkl\", \"intel\") in [\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36mthreadpool_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreadpool_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36mthreadpool_info\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mIn\u001b[0m \u001b[0maddition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meach\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0minternal_api\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \"\"\"\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ThreadpoolInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_ALL_USER_APIS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_modules_with_dl_iterate_phdr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_enum_process_module_ex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[1;31m# Store the module if it is supported and selected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mkernel_32\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCloseHandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[1;34m(self, filepath)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    644\u001b[0m                              lambda: None)\n\u001b[0;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"OpenBLAS\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 클러스터링\n",
    "# -----------------------------------\n",
    "# 표준화된 데이터를 사용\n",
    "train_x, test_x = load_standarized_dataA()\n",
    "# -----------------------------------\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# 데이터는 표준화 등의 스케일을 갖추는 전처리가 이루어져야 함\n",
    "\n",
    "# 학습 데이터를 기반으로 Mini-Batch K-Means를 통한 변환 정의\n",
    "kmeans = MiniBatchKMeans(n_clusters=10, random_state=71)\n",
    "kmeans.fit(train_x)\n",
    "\n",
    "# 해당 클러스터를 예측\n",
    "train_clusters = kmeans.predict(train_x)\n",
    "test_clusters = kmeans.predict(test_x)\n",
    "\n",
    "# 각 클러스터 중심까지의 거리를 저장\n",
    "train_distances = kmeans.transform(train_x)\n",
    "test_distances = kmeans.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f288b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
