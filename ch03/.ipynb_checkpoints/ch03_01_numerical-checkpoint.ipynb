{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "965fc5eb",
   "metadata": {},
   "source": [
    "### 데이터의 다양한 전처리 방법 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a608e",
   "metadata": {},
   "source": [
    "### 학습 내용\n",
    " * 정규화, 표준화의 기본 실습\n",
    " * 로그 변환의 기본 실습\n",
    " * Box-Cox 변환의 기본 실습\n",
    " * Yeo-Johnson변환의 기본 실습\n",
    " * clipping, binning, 순위, RankGauss로 변환하는 것에 대한 기본 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a16e1",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebb6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_x는 학습 데이터(X), train_y는 Target(예측할 변수), test_x는 테스트 데이터\n",
    "# pandas의 DataFrame, Series의 자료형 사용(numpy의 array로 값을 저장하기도 함.)\n",
    "train = pd.read_csv('../input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('../input/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# 학습 데이터와 테스트 데이터의 원래 상태를 복제해 두기\n",
    "train_x_saved = train_x.copy()\n",
    "test_x_saved = test_x.copy()\n",
    "\n",
    "# 학습 데이터와 테스트 데이터를 반환하는 함수\n",
    "def load_data():\n",
    "    train_x, test_x = train_x_saved.copy(), test_x_saved.copy()\n",
    "    return train_x, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c80b61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 29), (10000, 28), (10000,), (10000, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, train_x.shape, train_y.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de9294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대상 특징(피처) 지정 - 수치 변수를 목록에 저장\n",
    "num_cols = ['age', 'height', 'weight', 'amount',\n",
    "            'medical_info_a1', 'medical_info_a2', 'medical_info_a3', 'medical_info_b1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562d526",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - 표준화\n",
    "  * 평균을 0으로, 표준편차를 1로 변경\n",
    "  * 기준이 되는 값은 학습 데이터 셋(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15992fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                6.221690e-17\n",
      "height            -2.822720e-15\n",
      "weight            -1.951661e-16\n",
      "amount            -2.140954e-16\n",
      "medical_info_a1   -4.767020e-17\n",
      "medical_info_a2   -3.677059e-17\n",
      "medical_info_a3    1.968870e-16\n",
      "medical_info_b1    2.520206e-16\n",
      "dtype: float64 age                1.00005\n",
      "height             1.00005\n",
      "weight             1.00005\n",
      "amount             1.00005\n",
      "medical_info_a1    1.00005\n",
      "medical_info_a2    1.00005\n",
      "medical_info_a3    1.00005\n",
      "medical_info_b1    1.00005\n",
      "dtype: float64\n",
      "age                0.002597\n",
      "height             0.005582\n",
      "weight            -0.017946\n",
      "amount            -0.013080\n",
      "medical_info_a1    0.005988\n",
      "medical_info_a2    0.008365\n",
      "medical_info_a3    0.002117\n",
      "medical_info_b1    0.025981\n",
      "dtype: float64 age                1.003940\n",
      "height             0.989233\n",
      "weight             1.004621\n",
      "amount             1.004529\n",
      "medical_info_a1    1.003076\n",
      "medical_info_a2    0.997363\n",
      "medical_info_a3    0.992721\n",
      "medical_info_b1    0.990133\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습 데이터를 기반으로 복수 열의 표준화를 정의(평균 0, 표준편차 1)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x[num_cols])\n",
    "\n",
    "# 표준화를 수행한 후 각 열을 치환\n",
    "train_x[num_cols] = scaler.transform(train_x[num_cols])\n",
    "test_x[num_cols] = scaler.transform(test_x[num_cols])\n",
    "\n",
    "# 결과적으로 평균은 0, 표준편차는 1로 매우 가깝게 만들어짐.\n",
    "print( train_x[num_cols].mean(), train_x[num_cols].std() )\n",
    "print( test_x[num_cols].mean(), test_x[num_cols].std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435a8c3",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - 표준화\n",
    "  * 평균을 0으로, 표준편차를 1로 변경\n",
    "  * 기준이 되는 값은 학습/테스트 결합 데이터 셋(train_x, test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172467b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               -0.001296\n",
      "height            -0.002806\n",
      "weight             0.008952\n",
      "amount             0.006525\n",
      "medical_info_a1   -0.002989\n",
      "medical_info_a2   -0.004188\n",
      "medical_info_a3   -0.001062\n",
      "medical_info_b1   -0.013054\n",
      "dtype: float64 age                0.998106\n",
      "height             1.005469\n",
      "weight             0.997727\n",
      "amount             0.997792\n",
      "medical_info_a1    0.998534\n",
      "medical_info_a2    1.001385\n",
      "medical_info_a3    1.003721\n",
      "medical_info_b1    1.004935\n",
      "dtype: float64\n",
      "age                0.001296\n",
      "height             0.002806\n",
      "weight            -0.008952\n",
      "amount            -0.006525\n",
      "medical_info_a1    0.002989\n",
      "medical_info_a2    0.004188\n",
      "medical_info_a3    0.001062\n",
      "medical_info_b1    0.013054\n",
      "dtype: float64 age                1.001988\n",
      "height             0.994593\n",
      "weight             1.002288\n",
      "amount             1.002261\n",
      "medical_info_a1    1.001555\n",
      "medical_info_a2    0.998695\n",
      "medical_info_a3    0.996365\n",
      "medical_info_b1    0.994969\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습 데이터와 테스트 데이터를 결합한 결과를 기반으로 복수 열의 표준화를 정의\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat([train_x[num_cols], test_x[num_cols]]))\n",
    "\n",
    "# 표준화 변환 후 데이터로 각 열을 치환\n",
    "train_x[num_cols] = scaler.transform(train_x[num_cols])\n",
    "test_x[num_cols] = scaler.transform(test_x[num_cols])\n",
    "\n",
    "# 결과적으로 평균은 0, 표준편차는 1로 매우 가깝게 만들어짐.\n",
    "print( train_x[num_cols].mean(), train_x[num_cols].std() )\n",
    "print( test_x[num_cols].mean(), test_x[num_cols].std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923c4fb",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - 표준화 (나쁜 예제)\n",
    "  * 평균을 0으로, 표준편차를 1로 변경\n",
    "  * 기준이 되는 값은 학습, 테스트 데이터 각각 정함.  나쁜 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad7fe3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                6.221690e-17\n",
      "height            -2.822720e-15\n",
      "weight            -1.951661e-16\n",
      "amount            -2.140954e-16\n",
      "medical_info_a1   -4.767020e-17\n",
      "medical_info_a2   -3.677059e-17\n",
      "medical_info_a3    1.968870e-16\n",
      "medical_info_b1    2.520206e-16\n",
      "dtype: float64 age                1.00005\n",
      "height             1.00005\n",
      "weight             1.00005\n",
      "amount             1.00005\n",
      "medical_info_a1    1.00005\n",
      "medical_info_a2    1.00005\n",
      "medical_info_a3    1.00005\n",
      "medical_info_b1    1.00005\n",
      "dtype: float64\n",
      "age                5.845689e-17\n",
      "height            -2.455292e-15\n",
      "weight             2.793654e-16\n",
      "amount            -3.348322e-16\n",
      "medical_info_a1   -1.731948e-18\n",
      "medical_info_a2   -9.181544e-17\n",
      "medical_info_a3    5.728751e-18\n",
      "medical_info_b1    4.193951e-16\n",
      "dtype: float64 age                1.00005\n",
      "height             1.00005\n",
      "weight             1.00005\n",
      "amount             1.00005\n",
      "medical_info_a1    1.00005\n",
      "medical_info_a2    1.00005\n",
      "medical_info_a3    1.00005\n",
      "medical_info_b1    1.00005\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 학습 데이터와 테스트 데이터를 각각 표준화(나쁜 예)\n",
    "scaler_train = StandardScaler()\n",
    "scaler_train.fit(train_x[num_cols])\n",
    "train_x[num_cols] = scaler_train.transform(train_x[num_cols])\n",
    "\n",
    "scaler_test = StandardScaler()\n",
    "scaler_test.fit(test_x[num_cols])\n",
    "test_x[num_cols] = scaler_test.transform(test_x[num_cols])\n",
    "\n",
    "# 결과적으로 평균은 0, 표준편차는 1로 매우 가깝게 만들어짐.\n",
    "print( train_x[num_cols].mean(), train_x[num_cols].std() )\n",
    "print( test_x[num_cols].mean(), test_x[num_cols].std() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fdaa4",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - 정규화(Min-Max 스케일링)\n",
    "  * 값을 0~1 사이로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d9ac2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                0.0\n",
      "height             0.0\n",
      "weight             0.0\n",
      "amount             0.0\n",
      "medical_info_a1    0.0\n",
      "medical_info_a2    0.0\n",
      "medical_info_a3    0.0\n",
      "medical_info_b1    0.0\n",
      "dtype: float64 age                1.0\n",
      "height             1.0\n",
      "weight             1.0\n",
      "amount             1.0\n",
      "medical_info_a1    1.0\n",
      "medical_info_a2    1.0\n",
      "medical_info_a3    1.0\n",
      "medical_info_b1    1.0\n",
      "dtype: float64\n",
      "age                0.000000\n",
      "height            -0.022861\n",
      "weight            -0.002340\n",
      "amount             0.000000\n",
      "medical_info_a1   -0.067708\n",
      "medical_info_a2   -0.047919\n",
      "medical_info_a3    0.000000\n",
      "medical_info_b1    0.000000\n",
      "dtype: float64 age                1.000000\n",
      "height             1.050548\n",
      "weight             0.927204\n",
      "amount             1.000000\n",
      "medical_info_a1    0.963542\n",
      "medical_info_a2    1.003783\n",
      "medical_info_a3    1.000000\n",
      "medical_info_b1    1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 학습 데이터를 기반으로 여러 열의 최소-최대 스케일링 정의\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x[num_cols])\n",
    "\n",
    "# 정규화(0~1) 변환 후의 데이터로 각 열을 치환\n",
    "train_x[num_cols] = scaler.transform(train_x[num_cols])\n",
    "test_x[num_cols] = scaler.transform(test_x[num_cols])\n",
    "\n",
    "# 결과적으로 평균은 0, 표준편차는 1로 매우 가깝게 만들어짐.\n",
    "print( train_x[num_cols].min(), train_x[num_cols].max() )\n",
    "print( test_x[num_cols].min(), test_x[num_cols].max() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afd3a77",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - 로그 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544fb37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 값 :  [1.e+00 1.e+01 1.e+02 1.e+03 1.e+04]\n",
      "단순로그 값 x1:  [0.         2.30258509 4.60517019 6.90775528 9.21034037]\n",
      "log1p로그 값 x2:  [0.69314718 2.39789527 4.61512052 6.90875478 9.21044037]\n",
      "x3:  [0.         2.30258509 4.60517019 6.90775528 9.21034037]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 로그 변환\n",
    "# -----------------------------------\n",
    "x = np.array([1.0, 10.0, 100.0, 1000.0, 10000.0])\n",
    "\n",
    "# 단순히 값에 로그를 취함\n",
    "x1 = np.log(x)\n",
    "\n",
    "# 1을 더한 뒤에 로그를 취함\n",
    "x2 = np.log1p(x)\n",
    "\n",
    "# 절댓값의 로그를 취한 후, 원래의 부호를 추가\n",
    "x3 = np.sign(x) * np.log(np.abs(x))\n",
    "\n",
    "print(\"원래 값 : \", x)\n",
    "print(\"단순로그 값 x1: \", x1)\n",
    "print(\"log1p로그 값 x2: \", x2)\n",
    "print(\"x3: \", x3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9991ffe",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - Box-Cox 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e9514",
   "metadata": {},
   "source": [
    "* Box-Cox 변환은 데이터를 정규 분포에 가깝게 만들기 위해 사용되는 데이터 변환의 한 유형\n",
    "* 데이터의 특성을 파악하며, 비선형성을 줄여 정규성을 향상시키는데 도움이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7862b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "# -----------------------------------\n",
    "\n",
    "# 양의 정숫값만을 취하는 변수를 변환 대상으로 목록에 저장\n",
    "# 또한, 결측값을 포함하는 경우는 (~(train_x[c] <= 0.0)).all() 등으로 해야 하므로 주의\n",
    "pos_cols = [c for c in num_cols if (train_x[c] > 0.0).all() and (test_x[c] > 0.0).all()]\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# 학습 데이터를 기반으로 복수 열의 박스-칵스 변환 정의\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "pt.fit(train_x[pos_cols])\n",
    "\n",
    "# 변환 후의 데이터로 각 열을 치환\n",
    "train_x[pos_cols] = pt.transform(train_x[pos_cols])\n",
    "test_x[pos_cols] = pt.transform(test_x[pos_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa52b48",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - Yeo-Johnson변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f68062",
   "metadata": {},
   "source": [
    "* Yeo-Johnson 변환은 Box-Cox 변환을 일반화한 변환\n",
    "* Yeo-Johnson 변환은 Box-Cox 변환과 동일한 방식으로 작동하지만, 변환 계수 λ의 범위가 더 넓다.\n",
    "* Yeo-Johnson 변환의 변환 계수 λ는 -1에서 무한대까지의 값을 가질 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469d2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "# -----------------------------------\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# 학습 데이터를 기반으로 복수 열의 여-존슨 변환 정의\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "pt.fit(train_x[num_cols])\n",
    "\n",
    "# 변환 후의 데이터로 각 열을 치환\n",
    "train_x[num_cols] = pt.transform(train_x[num_cols])\n",
    "test_x[num_cols] = pt.transform(test_x[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ede7b",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b216d",
   "metadata": {},
   "source": [
    "* Clipping은 이상치나 극단적인 값에 대한 영향을 줄이고 모델의 안정성을 높이기 위해 사용.\n",
    "* 상한값과 하한값을 지정하여 데이터의 값이 상한을 초과하면 상한값으로 대체, 하한값 미만이면 하한값으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "382167ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daniel_wj\\AppData\\Local\\Temp\\ipykernel_18644\\3007283885.py:12: FutureWarning: Downcasting integer-dtype results in .where is deprecated and will change in a future version. To retain the old behavior, explicitly cast the results to the desired dtype.\n",
      "  train_x[num_cols] = train_x[num_cols].clip(p01, p99, axis=1)\n",
      "C:\\Users\\daniel_wj\\AppData\\Local\\Temp\\ipykernel_18644\\3007283885.py:13: FutureWarning: Downcasting integer-dtype results in .where is deprecated and will change in a future version. To retain the old behavior, explicitly cast the results to the desired dtype.\n",
      "  test_x[num_cols] = test_x[num_cols].clip(p01, p99, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# clipping\n",
    "# -----------------------------------\n",
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "# -----------------------------------\n",
    "# 열마다 학습 데이터의 1%, 99% 지점을 확인\n",
    "p01 = train_x[num_cols].quantile(0.01)\n",
    "p99 = train_x[num_cols].quantile(0.99)\n",
    "\n",
    "# 1％점 이하의 값은 1%점으로, 99%점 이상의 값은 99%점으로 클리핑\n",
    "train_x[num_cols] = train_x[num_cols].clip(p01, p99, axis=1)\n",
    "test_x[num_cols] = test_x[num_cols].clip(p01, p99, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34ceb7",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af4e30",
   "metadata": {},
   "source": [
    "* Binning은 연속적인 수치형 데이터를 구간 또는 범주로 분할하는 과정입니다. Binning은 데이터의 복잡성을 감소시키고, 모델의 성능을 향상시키기 위해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29e3a995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 1 2 0]\n",
      "[0 2 1 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 7, 5, 4, 6, 3]\n",
    "\n",
    "# 팬더스 라이브러리의 cut 함수로 구간분할 수행\n",
    "\n",
    "# bin의 수를 지정할 경우\n",
    "binned = pd.cut(x, 3, labels=False)\n",
    "print(binned)\n",
    "# [0 2 1 1 2 0] - 변환된 값은 세 구간(0, 1, 2)를 만들고 원본 x의 값이 어디에 해당되는지 나타냄\n",
    "\n",
    "# bin의 범위를 지정할 경우(3.0 이하, 3.0보다 크고 5.0보다 이하, 5.0보다 큼)\n",
    "bin_edges = [-float('inf'), 3.0, 5.0, float('inf')]\n",
    "binned = pd.cut(x, bin_edges, labels=False)\n",
    "print(binned)\n",
    "# [0 2 1 1 2 0] - 변환된 값은 세 구간을 만들고 원본 x의 값이 어디에 해당되는지 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c4994",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - 순위로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a936abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.  3.  4.  1.  5.5 5.5]\n",
      "[1 2 3 0 4 5]\n"
     ]
    }
   ],
   "source": [
    "x = [10, 20, 30, 0, 40, 40]\n",
    "\n",
    "# 팬더스의 rank 함수로 순위 변환\n",
    "rank = pd.Series(x).rank()\n",
    "print(rank.values)\n",
    "# 시작이 1, 같은 순위가 있을 경우에는 평균 순위가 됨\n",
    "# [2. 3. 4. 1. 5.5 5.5]\n",
    "\n",
    "# 넘파이의 argsort 함수를 2회 적용하는 방법으로 순위 변환\n",
    "order = np.argsort(x)\n",
    "rank = np.argsort(order)\n",
    "print(rank)\n",
    "# 넘파이의 argsort 함수를 2회 적용하는 방법으로 순위 변환\n",
    "# [1 2 3 0 4 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc23ae06",
   "metadata": {},
   "source": [
    "### 데이터 전처리 - RankGauss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da548df9",
   "metadata": {},
   "source": [
    "* RankGauss는 수치형 데이터의 분포를 정규 분포에 가깝게 만들기 위해 사용되는 변환 방법 중 하나\n",
    "* 이 방법은 데이터를 순위(rank)로 변환한 후, 변환된 순위에 대해 가우시안 정규화를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9987e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽어오기\n",
    "train_x, test_x = load_data()\n",
    "# -----------------------------------\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "# 학습 데이터를 기반으로 복수 열의 RankGauss를 통한 변환 정의\n",
    "transformer = QuantileTransformer(n_quantiles=100, random_state=0, output_distribution='normal')\n",
    "transformer.fit(train_x[num_cols])\n",
    "\n",
    "# 변환 후의 데이터로 각 열을 치환\n",
    "train_x[num_cols] = transformer.transform(train_x[num_cols])\n",
    "test_x[num_cols] = transformer.transform(test_x[num_cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
